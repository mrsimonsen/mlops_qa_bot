# mlops_qa_bot
An end-to-end RAG-based Q&amp;A bot for the MLOps stack. The project uses Ollama for local LLM inference, ZenML for pipeline orchestration, and is automatically deployed to AWS EC2 via Terraform and GitHub Actions.

## Tools Used
* Git
* DVC
* GitHub Actions
* llama3
* ZenML
* MLflow
* Docker
* AWS EC2
* Terraform