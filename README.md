# mlops_qa_bot
An end-to-end RAG-based Q&amp;A bot for the MLOps stack. The project uses Ollama for local LLM inference, ZenML for pipeline orchestration, and is automatically deployed to AWS EC2 via Terraform and GitHub Actions.
